# HSE_AntiPlagiarismSystem

Конструирование программного обеспечения. Контрольная работа №2. Синхронное межсервисное взаимодействие. 

Архитектура

Решение состоит из четырёх основных компонентов:

1. `API Gateway` (проект `AntiPlagiarism.ApiGateway`)
    - Единая точка входа для клиентских запросов
    - Маршрутизация запросов к соответствующим микросервисам
    - Проксирование HTTP-запросов
    - Обработка ошибок и форматирование ответов 
2. `File Storing Service` (проект `AntiPlagiarism.FileStoringService`)
    - Загрузка файлов
    - Хранение файлов в локальной файловой системе
    - Предоставление API для доступа к файлам
    - Хранение метаданных в PostgreSQL
3. `File Analysis Service` (проект `AntiPlagiarism.FileAnalysisService`)
    - Анализ текстовых файлов (подсчёт слов, абзацев, символов)
    - Обнаружение плагиата на основе хеширования содержимого (SHA-256)
    - Генерация облака слов
    - Хранение результатов анализа в PostgreSQL 
4. Проект `AntiPlagiarism.Common`
    - Общие DTO для обмена данными между микросервисами
    - Утилиты (в данном случае одна `HashUtility` для вычисления SHA-256 хешей)



Синхронное межсервисное взаимодействие

Микросервисы взаимодействуют через HTTP-запросы:
- от `API Gateway` к `File Storing Service`: загрузка и получение файлов
- от `API Gateway к File Analysis Service`: запрос на анализ файлов и получение результатов 
- от `File Analysis Service` к `File Storing Service`: получение содержимого файлов для анализа


База данных

Используется PostgreSQL с двумя отдельными базами данных:
1. file_storage
    - Схема `storage` 
    - Таблица `files`: хранит метаданные загруженных файлов (ID, имя, местоположение)
2. file_analysis
    - Схема `analysis`
    - Таблица `analysis_results`: результаты анализа текста
    - Таблица `plagiarism_checks`: информация о проверке на плагиат, включая хеши файлов

Инициализация базы данных производится автоматически при запуске контейнеров через скрипты в директории `init-db`


Алгоритм обнаружения плагиата
Система исользует подход с хешированием полного содержимого документа:
1. Когда файл отправляется на анализ, система вычисляет SHA-256 хеш его содержимого
2. Хеш сравнивается со всеми ранее сохранёнными хешами в базе данных
3. Если обнаружено совпадение, файл помечается как плагиат и указывается ID оригинального документа
4. Результат сохраняется в базе данных для будущих сравнений

Это соответствует второму варианту изменения, которое предлагалось в пользовательский сценарий:
"`Не игнорируем данное условие. Считаем файлы в системе не уникальны - при загрузке файла в систему ему каждый раз присваивается новый id и в рамках анализа файлов происходит проверка на антиплагиат (тогда разумнее передать ответственность за хранения хэша файла сервису аналитики). Тогда предлагаемые схемы не достоверны. Но в целом схемы это не требования, а ориентир - как можно реализовать. От них можно (и нужно) отступать, только следует указать это в отчете.`"

Дополнительные возможности

Генерация облака слов

Система автоматически создаёт визуализацию частотности слов в документах (облака слов):
 - Генерация выполняется через `QuickChart Word Cloud API`
 - Настраиваемые параметры: размер, шрифт, цвета, масштабирование
 - Исключение стоп-слов для более информативной визуализации
 - Сохранение изображений в выделенном хранилище



Анализ текста

Для каждого документа рассчитываются:
 - Количество абзацев
 - Количество слов
 - Количество символов 



Docker volumes

Системой используются три постоянных хранилища:
- `postgres-data`: данные PostgreSQL
- `file-storage-data`: загруженные файлы
- `wordcloud-storage-data`: изображения облаков слов



API Endpoints

1. File Storing Service
 - `POST /api/files/upload` - загрузка файла
 - `GET /api/files/{id}` - Получение файла по ID

2. File Analysis Service

 - `POST /api/file-analysis/analyze/{fileId}` - Анализ файла и проверка на плагиат
 - `GET /api/file-analysis/wordcloud/{location}` - Получение изображения облака слов

3. API Gateway (проксирует все запросы к соответствующим сервисам)

 - `POST /api/files/upload` -> File Storing Service
 - `GET /api/files/{id}` -> File Storing Service
 - `POST /api/file-analysis/analyze/{fileId}` -> File Analysis Service
 - `GET /api/file-analysis/wordcloud/{location}` -> File Analysis Service


Запуск:

`docker-compose build` - сборка контейнеров
`docker-compose up -d` - запуск контейнеров

Примеры работы:

1. Загрузка файла (файл ради удобства я располагал на одном уровне с решением `sln`):

`curl -X POST -F "file=@test.txt" http://localhost:8080/api/files/upload`

Пример ответа:

`{"id":"4a59649c-a27c-4e25-a047-546fff275f6e","name":"test.txt","location":"07b96ec5-974c-46ca-9b14-7fcdbe782113-test.txt"}`


2. Анализ файла:

`curl -X POST -H "Content-Type: application/json" -d "{}" http://localhost:8080/api/file-analysis/analyze/4a59649c-a27c-4e25-a047-546fff275f6e`

Пример ответа (отформатировано в несколько строк ради наглядности):

`{"fileId":"4a59649c-a27c-4e25-a047-546fff275f6e",`
` "paragraphCount":7,`
`"wordCount":299,`
`"characterCount":1534`
`"wordCloudLocation":"681437bb-2be1-4533-ae12-7b55f82cfeb6-wordcloud-4a59649c-a27c-4e25-a047-546fff275f6e.png",`
`"isPlagiarism":false,`
`"originalFileId":null}`


3. Получение облака слов:

`curl -s -o wordcloudtest.png http://localhost:8080/api/file-analysis/wordcloud/681437bb-2be1-4533-ae12-7b55f82cfeb6-wordcloud-4a59649c-a27c-4e25-a047-546fff275f6e.png && echo "Файл успешно загружен"`

Вывод в терминал:

`Файл успешно загружен`

(при этом в директорию с решением добавляется файл с названием `wordcloudtest.png`)


4. Получение текстового файла:

`curl -s -o downloaded_file.txt http://localhost:8080/api/files/4a59649c-a27c-4e25-a047-546fff275f6e && echo "Файл успешно загружен"`


Вывод в терминал:

`Файл успешно загружен`

(при этом в директорию с решением добавляется файл с названием downloaded_file.txt)

5. Проверка на антиплагиат (обнаружение плагиата)

Для начала я загрузил просто скачанный в предыдущем действии файл, но я опустил этот шаг

`curl -X POST -H "Content-Type: application/json" -d "{}" http://localhost:8080/api/file-analysis/analyze/39b0d3bb-19aa-4929-aa07-f9dd6d55fed9`


Ответ в терминале:

`{"fileId":"39b0d3bb-19aa-4929-aa07-f9dd6d55fed9",`
`"paragraphCount":7,`
`"wordCount":299,`
`"characterCount":1534,`
`"wordCloudLocation":"22ee59a4-5b44-4bd2-906e-145aea37f574-wordcloud-39b0d3bb-19aa-4929-aa07-f9dd6d55fed9.png",`
`"isPlagiarism":true,`
`"originalFileId":"4a59649c-a27c-4e25-a047-546fff275f6e"}`

Плагиат зарегистрирован!

Также можно увидеть API Эндпоинты и сделать запросы с помощью Swagger UI. Открывается по адресу `http://localhost:8080/swagger/index.html`

Нюанс: чтобы зарегистрировать, что один файл аналогичен с другим, надо совершить анализ предыдущего файла, чтобы можно было сравнивать вычисленные хеши. Поэтому, если загружать файл, то лучше следующим же действием сделать анализ.

Механизм инициализации базы данных
Вместо миграций Entity Framework система использует SQL-скрипты для инициализации схемы базы данных. Скрипты выполняются автоматически при первом запуске контейнера PostgreSQL.



## Тестирование системы

Система Anti-Plagiarism включает в себя четыре проекта модульных тестов, обеспечивающих проверку всех ключевых компонентов:

### AntiPlagiarism.Common.Tests

Тесты для общей библиотеки:

- **HashUtilityTests**: Проверка корректности вычисления SHA-256 хешей
  - Тестирование правильности вычисления хешей для известных значений
  - Проверка сброса позиции потока после вычисления хеша
  
- **DTO Tests**: Проверка корректности работы объектов передачи данных
  - `FileUploadResponseDtoTests`
  - `FileAnalysisResultDtoTests`
  - `WordCloudResponseDtoTests`
  - `FileDtoTests`
  - `FileContentResponseDtoTests`

### AntiPlagiarism.FileStoringService.Tests

Тесты для сервиса хранения файлов:

- **LocalFileStorageTests**: Проверка функциональности хранилища файлов
  - Тестирование сохранения файлов
  - Проверка чтения файлов
  - Обработка ошибок при отсутствии файла

- **FileRepositoryTests**: Проверка работы с базой данных
  - Сохранение новых записей о файлах
  - Получение метаданных файлов по ID
  - Обработка несуществующих ID

### AntiPlagiarism.FileAnalysisService.Tests

Тесты для сервиса анализа файлов:

- **FileAnalysisServiceTests**: Проверка основной бизнес-логики
  - Анализ файлов с существующими результатами
  - Анализ новых файлов, не являющихся плагиатом
  - Обнаружение плагиата при совпадении хешей
  - Генерация облаков слов

- **FileAnalysisResultRepositoryTests**: Проверка репозитория результатов анализа
  - Сохранение результатов анализа
  - Получение результатов по ID файла

- **PlagiarismCheckRepositoryTests**: Проверка репозитория проверок на плагиат
  - Получение записи по ID файла
  - Получение записи по хешу
  - Сохранение новых проверок на плагиат

- **WordCloudStorageTests**: Проверка хранилища облаков слов
  - Сохранение изображений
  - Получение изображений по имени
  - Обработка отсутствующих изображений

### AntiPlagiarism.ApiGateway.Tests

Тесты для API шлюза:

- **ProxyServiceTests**: Проверка работы проксирования запросов
  - Проксирование простых GET-запросов
  - Проксирование POST-запросов с JSON телом
  - Проксирование POST-запросов с form-data
  - Обработка ошибок при проксировании

## Подход к тестированию

В проекте используется комбинация различных подходов к тестированию:

1. **Модульное тестирование**: Изоляция отдельных компонентов с использованием моков (с помощью библиотеки Moq)
2. **Интеграционное тестирование**: Проверка взаимодействия компонентов
3. **In-Memory тестирование базы данных**: Использование InMemoryDatabase для тестирования репозиториев
4. **Тестирование файловой системы**: Создание временных директорий для тестирования хранилищ файлов

Все тесты реализованы с использованием фреймворка `xUnit` и предоставляют хорошее покрытие кода, обеспечивая надежность системы.

Запуск тестирования производился в IDE Rider из-за удобного интерфейса и показа в процентах покрытия тестирования. Покрытие соответствует требуемому в условии задания. Вообщем, тестирование покрывает бизнес-логику и даже больше.


Итог: задание соответствует всем требованиям, предъявляемым условием.